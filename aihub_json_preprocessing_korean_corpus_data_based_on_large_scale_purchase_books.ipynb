{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIHub Json Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kss==3.7.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KSS Argument Error: Restart Jupyter Kernel Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-mecab-ko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KSS 3.7.3 matches python-mecab-ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import kss\n",
    "import ray\n",
    "import json\n",
    "import time\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from mecab import MeCab\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AIHUB'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIHUB 대규모 구매도서 기반 한국어 말뭉치 데이터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=624)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert JSON File to TXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import make_json_txt_file_path_list\n",
    "from data_preprocessing import count_number_of_txt_file_with_batch_list\n",
    "from data_preprocessing import write_jsontext_to_txt_file_with_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_list = ['AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/000/'+ '/**/*.json']\n",
    "txt_path_list = [\"exploration/korean_corpus_data_based_on_large_scale_purchase_books_pro/AIHUB_korean_corpus_data_based_on_large_scale_purchase_books_\"]\n",
    "corpus_name = \"korean_corpus_data_based_on_large_scale_purchase_books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of file: 51\n"
     ]
    }
   ],
   "source": [
    "json_file_list, txt_file_path_list = \\\n",
    "    make_json_txt_file_path_list(json_path_list, txt_path_list, corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 100\n",
      "The number of txt file: 8900\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "corpus_name = 'korean_corpus_data_based_on_large_scale_purchase_books'\n",
    "the_number_of_txt_file, the_number_of_txt_file_list = count_number_of_txt_file_with_batch_list(json_file_list, batch_size, corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>Length of Source List</th>\n",
       "      <th>The Number of txt File</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17494</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18269</td>\n",
       "      <td>183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>20049</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18494</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17708</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18290</td>\n",
       "      <td>183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17544</td>\n",
       "      <td>176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17932</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17902</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17958</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18693</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18129</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18316</td>\n",
       "      <td>184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18028</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18010</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17931</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18536</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18241</td>\n",
       "      <td>183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18349</td>\n",
       "      <td>184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18131</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18201</td>\n",
       "      <td>183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17534</td>\n",
       "      <td>176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17758</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17824</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18161</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18127</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17898</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17752</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17580</td>\n",
       "      <td>176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18031</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18386</td>\n",
       "      <td>184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17497</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17497</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17844</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18274</td>\n",
       "      <td>183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17994</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17831</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18026</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17563</td>\n",
       "      <td>176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17917</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18336</td>\n",
       "      <td>184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18161</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18407</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>18575</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17494</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17719</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17516</td>\n",
       "      <td>176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17996</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>17683</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...</td>\n",
       "      <td>3925</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               File  \\\n",
       "0            0                                                  0   \n",
       "1            1  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "2            2  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "3            3  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "4            4  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "5            5  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "6            6  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "7            7  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "8            8  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "9            9  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "10          10  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "11          11  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "12          12  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "13          13  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "14          14  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "15          15  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "16          16  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "17          17  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "18          18  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "19          19  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "20          20  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "21          21  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "22          22  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "23          23  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "24          24  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "25          25  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "26          26  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "27          27  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "28          28  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "29          29  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "30          30  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "31          31  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "32          32  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "33          33  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "34          34  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "35          35  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "36          36  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "37          37  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "38          38  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "39          39  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "40          40  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "41          41  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "42          42  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "43          43  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "44          44  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "45          45  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "46          46  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "47          47  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "48          48  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "49          49  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "50          50  AIHUB_대규모 구매도서 기반 한국어 말뭉치 데이터/sample/라벨링데이터/00...   \n",
       "\n",
       "    Length of Source List  The Number of txt File  Description  \n",
       "0                       0                       0          0.0  \n",
       "1                   17494                     175          NaN  \n",
       "2                   18269                     183          NaN  \n",
       "3                   20049                     201          NaN  \n",
       "4                   18494                     185          NaN  \n",
       "5                   17708                     178          NaN  \n",
       "6                   18290                     183          NaN  \n",
       "7                   17544                     176          NaN  \n",
       "8                   17932                     180          NaN  \n",
       "9                   17902                     180          NaN  \n",
       "10                  17958                     180          NaN  \n",
       "11                  18693                     187          NaN  \n",
       "12                  18129                     182          NaN  \n",
       "13                  18316                     184          NaN  \n",
       "14                  18028                     181          NaN  \n",
       "15                  18010                     181          NaN  \n",
       "16                  17931                     180          NaN  \n",
       "17                  18536                     186          NaN  \n",
       "18                  18241                     183          NaN  \n",
       "19                  18349                     184          NaN  \n",
       "20                  18131                     182          NaN  \n",
       "21                  18201                     183          NaN  \n",
       "22                  17534                     176          NaN  \n",
       "23                  17758                     178          NaN  \n",
       "24                  17824                     179          NaN  \n",
       "25                  18161                     182          NaN  \n",
       "26                  18127                     182          NaN  \n",
       "27                  17898                     179          NaN  \n",
       "28                  17752                     178          NaN  \n",
       "29                  17580                     176          NaN  \n",
       "30                  18031                     181          NaN  \n",
       "31                  18386                     184          NaN  \n",
       "32                  17497                     175          NaN  \n",
       "33                  17497                     175          NaN  \n",
       "34                  17844                     179          NaN  \n",
       "35                  18274                     183          NaN  \n",
       "36                  17994                     180          NaN  \n",
       "37                  17831                     179          NaN  \n",
       "38                  18026                     181          NaN  \n",
       "39                  17563                     176          NaN  \n",
       "40                  17917                     180          NaN  \n",
       "41                  18336                     184          NaN  \n",
       "42                  18161                     182          NaN  \n",
       "43                  18407                     185          NaN  \n",
       "44                  18575                     186          NaN  \n",
       "45                  17494                     175          NaN  \n",
       "46                  17719                     178          NaN  \n",
       "47                  17516                     176          NaN  \n",
       "48                  17996                     180          NaN  \n",
       "49                  17683                     177          NaN  \n",
       "50                   3925                      40          NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_by_batch_df = pd.read_excel('source_file_by_batch/korean_corpus_data_based_on_large_scale_purchase_books.xlsx', engine='openpyxl')  \n",
    "source_file_by_batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Size]\n",
      "The number of preprocessing corpus: 8900\n",
      "\n",
      "[Order]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8900/8900 [06:52<00:00, 21.59it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "corpus_name = \"korean_corpus_data_based_on_large_scale_purchase_books\"\n",
    "write_jsontext_to_txt_file_with_batch_list(json_file_list, txt_file_path_list, batch_size, the_number_of_txt_file_list, corpus_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess TXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_segmentation import preprocessing_text\n",
    "from data_preprocessing import make_pro_post_txt_file_path_list\n",
    "from data_preprocessing import merge_and_deduplicate_corpus_txt\n",
    "from reading_data import reading_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_corpus_path = \"AIHUB_corpus/exploration/korean_corpus_data_based_on_large_scale_purchase_books_pro/AIHUB_korean_corpus_data_based_on_large_scale_purchase_books_\" + \"*.txt\"\n",
    "pro_post_xlsx_path = \"pro_post_corpus_path/korean_corpus_data_based_on_large_scale_purchase_books.xlsx\"\n",
    "pro_total_corpus_path_list, post_total_corpus_path_list = make_pro_post_txt_file_path_list(pro_corpus_path, pro_post_xlsx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pro_total_corpus_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_coprus_file = pro_total_corpus_path_list[0]\n",
    "line_length = 1\n",
    "data_type = \"source\"\n",
    "\n",
    "reading_txt(pro_coprus_file, line_length, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_coprus_file = pro_total_corpus_path_list[0]\n",
    "line_length = 1\n",
    "data_type = \"preprocessing\"\n",
    "\n",
    "reading_txt(pro_coprus_file, line_length, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m txt_preprocessing \\\n",
    "    --num_cpus 4 \\\n",
    "    --pro_post_xlsx_path 'pro_post_corpus_path/korean_corpus_data_based_on_large_scale_purchase_books.xlsx' \\\n",
    "    --start_index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_corpus_path = \"AIHUB_corpus/exploration/korean_corpus_data_based_on_large_scale_purchase_books_post/AIHUB_korean_corpus_data_based_on_large_scale_purchase_books_\" +\"*.txt\"\n",
    "merge_corpus_path = 'AIHUB_corpus/duplicate/AIHUB_korean_corpus_data_based_on_large_scale_purchase_books.txt'\n",
    "deduplicate_corpus_path = 'AIHUB_corpus/AIHUB_korean_corpus_data_based_on_large_scale_purchase_books.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_and_deduplicate_corpus_txt(preprocessing_corpus_path, merge_corpus_path, \n",
    "                                  deduplicate_corpus_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus_05",
   "language": "python",
   "name": "corpus_05"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
