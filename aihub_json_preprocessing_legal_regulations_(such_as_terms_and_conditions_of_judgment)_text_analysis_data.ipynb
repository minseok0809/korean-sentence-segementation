{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIHub Json Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kss==3.7.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KSS Argument Error: Restart Jupyter Kernel Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-mecab-ko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KSS 3.7.3 matches python-mecab-ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import kss\n",
    "import ray\n",
    "import json\n",
    "import time\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from mecab import MeCab\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\AIHUB'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIHUB 법률 규정 (판결서 약관 등) 텍스트 분석 데이터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://aihub.or.kr/aihubdata/data/view.do?currMenu=116&topMenu=100&aihubDataSe=ty&dataSetSn=580)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert JSON File to TXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import make_train_valid_json_txt_file_path_list\n",
    "from data_preprocessing import divide_source_file_list\n",
    "from extract_source_text import make_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_list = ['AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training' + '/**/*.json',\n",
    "             'AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation' + '/**/*.json']\n",
    "txt_path_list = [\"exploration/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_pro/AIHUB_legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_train_\", \n",
    "                 \"exploration/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_pro/AIHUB_legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_valid_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of file: 9450\n"
     ]
    }
   ],
   "source": [
    "train_json_file_list, valid_json_file_list, train_txt_file_path_list, valid_txt_file_path_list = \\\n",
    "    make_train_valid_json_txt_file_path_list(json_path_list, txt_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_index_df = pd.DataFrame(train_json_file_list, columns=['source_file_name'])\n",
    "source_file_index_df.to_excel(\"source_file_index/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_source_train_file_index.xlsx\", index=False)\n",
    "\n",
    "source_file_index_df = pd.DataFrame(valid_json_file_list, columns=['source_file_name'])\n",
    "source_file_index_df.to_excel(\"source_file_index/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_source_valid_file_index.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_number_of_txt_file_with_batch_list(source_file_list, batch_size):\n",
    "    \n",
    "    source_file_by_batch_df = pd.DataFrame({'File':[0], 'Length of Source List':[0],\n",
    "                                            'The Number of txt File':[0], \n",
    "                                            'Description':[0]})\n",
    "    the_number_of_total_txt_file = 0\n",
    "    the_number_of_txt_file_list = []\n",
    "    source_list = []\n",
    "    \n",
    "    for i in range(len(source_file_list)):    \n",
    "        \n",
    "        source_file = source_file_list[i]   \n",
    "            \n",
    "        with open(source_file, 'r', encoding='utf-8') as one_json_file:\n",
    "            one_json_sample = json.load(one_json_file) \n",
    "\n",
    "        sources = make_sources(source_file, one_json_sample)\n",
    "        for source in sources:\n",
    "            source_list.append(source[0])\n",
    "            \n",
    "        the_number_of_txt_file = 1\n",
    "\n",
    "        if len(source_list) >= batch_size:\n",
    "            source_file_by_batch_df.loc[i] = [source_file,\n",
    "                                              len(source_list), the_number_of_txt_file, \"\"]\n",
    "              \n",
    "        elif len(source_list) < batch_size:\n",
    "            source_file_by_batch_df.loc[i] = [source_file,\n",
    "                                              len(source_list), the_number_of_txt_file,\n",
    "                                              \"not subject of batch. small source list.\"]\n",
    "            \n",
    "        the_number_of_txt_file_list.append(len(source_list))\n",
    "        the_number_of_total_txt_file += len(source_list) \n",
    "        source_list = []\n",
    "\n",
    "    the_number_of_total_txt_file = the_number_of_total_txt_file // batch_size                 \n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"The number of txt file:\", the_number_of_total_txt_file)\n",
    "\n",
    "    source_file_by_batch_df = source_file_by_batch_df.astype({'Length of Source List':'int', \n",
    "                                                              'The Number of txt File':'int'})\n",
    "    \n",
    "    if 'rain' in source_file:\n",
    "        source_file_by_batch_df.to_excel(\"source_file_by_batch/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_train.xlsx\", index=False)\n",
    "    elif 'alid' in source_file:\n",
    "        source_file_by_batch_df.to_excel(\"source_file_by_batch/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_valid.xlsx\", index=False)\n",
    "    else:\n",
    "         source_file_by_batch_df.to_excel(\"source_file_by_batch/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data.xlsx\", index=False)\n",
    "    \n",
    "    return the_number_of_total_txt_file, the_number_of_txt_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsontext_to_txt_file_with_batch_list(source_file_list,\n",
    "                                    text_file_path_list,\n",
    "                                    batch_size, the_number_of_txt_file_list):\n",
    "\n",
    "  progress_length = sum(the_number_of_txt_file_list) // batch_size\n",
    "  print(\"[Size]\")\n",
    "  print(\"The number of preprocessing corpus: \" + str(progress_length))\n",
    "  print(\"\\n[Order]\")\n",
    "  source_list = []\n",
    "  pbar = tqdm(range(progress_length))\n",
    "  num = 0\n",
    "  \n",
    "  for i in range(len(source_file_list)):\n",
    "\n",
    "    source_file = source_file_list[i]\n",
    "        \n",
    "    with open(source_file, 'r', encoding='utf-8') as one_json_file:\n",
    "      one_json_sample = json.load(one_json_file)\n",
    "      \n",
    "    sources = make_sources(source_file, one_json_sample)\n",
    "\n",
    "    if len(source_list) >= batch_size:\n",
    "        with open(os.path.join('AIHUB_corpus/' + text_file_path_list[i][:-4] + \".txt\"), \"a\", encoding='utf-8') as fp:        \n",
    "            fp.write(\"\\n\".join(source_list)) \n",
    "        pbar.n += 1\n",
    "        pbar.refresh()\n",
    "        time.sleep(0.01)  \n",
    "  \n",
    "        source_list = []\n",
    "          \n",
    "    elif i == (len(source_file_list) -1): \n",
    "        for source in sources:\n",
    "          source_list.append(source)\n",
    "        \n",
    "        with open(os.path.join('AIHUB_corpus/' + text_file_path_list[i][:-4] + \".txt\"), \"a\", encoding='utf-8') as fp:        \n",
    "            fp.write(\"\\n\".join(source_list[0])) \n",
    "        num += 1  \n",
    "        pbar.n += 1\n",
    "        pbar.refresh()\n",
    "        time.sleep(0.01)\n",
    "                    \n",
    "    for source in sources:\n",
    "      source_list.append(source[0])   \n",
    "  pbar.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 1000\n",
      "The number of txt file: 30\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "the_number_of_txt_file, the_number_of_txt_file_list = count_number_of_txt_file_with_batch_list(train_json_file_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>Length of Source List</th>\n",
       "      <th>The Number of txt File</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>8395</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>8396</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>8397</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>8398</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>8399</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               File  \\\n",
       "0              0  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "1              1  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "2              2  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "3              3  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "4              4  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "...          ...                                                ...   \n",
       "8395        8395  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "8396        8396  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "8397        8397  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "8398        8398  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "8399        8399  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Training\\라벨링...   \n",
       "\n",
       "      Length of Source List  The Number of txt File  \\\n",
       "0                         2                       1   \n",
       "1                         2                       1   \n",
       "2                         2                       1   \n",
       "3                         2                       1   \n",
       "4                         2                       1   \n",
       "...                     ...                     ...   \n",
       "8395                     35                       1   \n",
       "8396                     15                       1   \n",
       "8397                     77                       1   \n",
       "8398                     55                       1   \n",
       "8399                     46                       1   \n",
       "\n",
       "                                   Description  \n",
       "0     not subject of batch. small source list.  \n",
       "1     not subject of batch. small source list.  \n",
       "2     not subject of batch. small source list.  \n",
       "3     not subject of batch. small source list.  \n",
       "4     not subject of batch. small source list.  \n",
       "...                                        ...  \n",
       "8395  not subject of batch. small source list.  \n",
       "8396  not subject of batch. small source list.  \n",
       "8397  not subject of batch. small source list.  \n",
       "8398  not subject of batch. small source list.  \n",
       "8399  not subject of batch. small source list.  \n",
       "\n",
       "[8400 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_by_batch_train_df = pd.read_excel('source_file_by_batch/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_train.xlsx', engine='openpyxl')  \n",
    "source_file_by_batch_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Size]\n",
      "The number of preprocessing corpus: 30\n",
      "\n",
      "[Order]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:10,  2.90it/s]                        \n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "write_jsontext_to_txt_file_with_batch_list(train_json_file_list, train_txt_file_path_list,\n",
    "                batch_size, the_number_of_txt_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 1000\n",
      "The number of txt file: 4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "the_number_of_txt_file, the_number_of_txt_file_list = count_number_of_txt_file_with_batch_list(valid_json_file_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>Length of Source List</th>\n",
       "      <th>The Number of txt File</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1046</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1047</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1048</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>not subject of batch. small source list.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               File  \\\n",
       "0              0  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "1              1  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "2              2  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "3              3  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "4              4  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "...          ...                                                ...   \n",
       "1045        1045  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "1046        1046  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "1047        1047  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "1048        1048  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "1049        1049  AIHUB_법률 규정 (판결서 약관 등) 텍스트 분석 데이터/Validation\\라...   \n",
       "\n",
       "      Length of Source List  The Number of txt File  \\\n",
       "0                         2                       1   \n",
       "1                         2                       1   \n",
       "2                         2                       1   \n",
       "3                         2                       1   \n",
       "4                         2                       1   \n",
       "...                     ...                     ...   \n",
       "1045                     56                       1   \n",
       "1046                     36                       1   \n",
       "1047                     28                       1   \n",
       "1048                     30                       1   \n",
       "1049                     31                       1   \n",
       "\n",
       "                                   Description  \n",
       "0     not subject of batch. small source list.  \n",
       "1     not subject of batch. small source list.  \n",
       "2     not subject of batch. small source list.  \n",
       "3     not subject of batch. small source list.  \n",
       "4     not subject of batch. small source list.  \n",
       "...                                        ...  \n",
       "1045  not subject of batch. small source list.  \n",
       "1046  not subject of batch. small source list.  \n",
       "1047  not subject of batch. small source list.  \n",
       "1048  not subject of batch. small source list.  \n",
       "1049  not subject of batch. small source list.  \n",
       "\n",
       "[1050 rows x 5 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_by_batch_valid_df = pd.read_excel('source_file_by_batch/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_valid.xlsx', engine='openpyxl')  \n",
    "source_file_by_batch_valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Size]\n",
      "The number of preprocessing corpus: 4\n",
      "\n",
      "[Order]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "write_jsontext_to_txt_file_with_batch_list(valid_json_file_list, valid_txt_file_path_list,\n",
    "                batch_size, the_number_of_txt_file_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess TXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_segmentation import preprocessing_text\n",
    "from data_preprocessing import make_pro_post_txt_file_path_list\n",
    "from data_preprocessing import merge_and_deduplicate_corpus_txt\n",
    "from reading_data import reading_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_corpus_path = \"AIHUB_corpus/exploration/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_pro/AIHUB_legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_\" + \"*.txt\"\n",
    "pro_total_corpus_path_list, post_total_corpus_path_list = make_pro_post_txt_file_path_list(pro_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pro_total_corpus_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제2조(보증금액)\n",
      "\n",
      " ① 이 보증서에 의한 보증금액은 채권자의 채무자에 대한 보증부대출 예정금액에 보증비율을 곱한 금액으로 합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pro_coprus_file = pro_total_corpus_path_list[0]\n",
    "line_length = 1\n",
    "data_type = \"source\"\n",
    "\n",
    "reading_txt(pro_coprus_file, line_length, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 보증서에 의한 보증금액은 채권자의 채무자에 대한 보증부대출 예정금액에 보증비율을 곱한 금액으로 합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pro_coprus_file = pro_total_corpus_path_list[0]\n",
    "line_length = 1\n",
    "data_type = \"preprocessing\"\n",
    "\n",
    "reading_txt(pro_coprus_file, line_length, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:08:05,201\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus = 4)\n",
    "\n",
    "@ray.remote\n",
    "def ray_preprocessing_text(source, corpus_path):\n",
    "\n",
    "    preprocessing_sentence_list = preprocessing_text(source, corpus_path)\n",
    "\n",
    "    return preprocessing_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_corpus_txt(pro_total_corpus_path_list, post_total_corpus_path_list):\n",
    "\n",
    "    progress_length = len(pro_total_corpus_path_list)\n",
    "    print(\"[Size]\")\n",
    "    print(\"The number of preprocessing corpus: \" + str(len(pro_total_corpus_path_list)))\n",
    "    print(\"\\n[Order]\")\n",
    "    pbar = tqdm(range(progress_length))\n",
    "    process_num = 10    \n",
    "\n",
    "    for pro, post in zip(pro_total_corpus_path_list, post_total_corpus_path_list):\n",
    "\n",
    "        sentence_list = []\n",
    "\n",
    "        with open(pro, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().splitlines() \n",
    "            nested_lines_num = len(lines) // process_num\n",
    "            for i in range(nested_lines_num - 1):\n",
    "                start_line = process_num * i\n",
    "                end_line = process_num * (i+1)\n",
    "                futures = [preprocessing_text.remote(lines[start_line:end_line][j], pro) for j in range(process_num)]\n",
    "                results = ray.get(futures)\n",
    "\n",
    "                if i == nested_lines_num - 2:\n",
    "                    futures = [preprocessing_text.remote(lines[end_line:][j], pro) for j in range(len(lines) - end_line)]\n",
    "                    results = ray.get(futures)\n",
    "\n",
    "                sentences = list(chain.from_iterable(results))\n",
    "                sentence_list.append(sentences)\n",
    "\n",
    "        sentence_list = list(chain.from_iterable(sentence_list))\n",
    "\n",
    "        with open(post, 'a', encoding='utf-8') as fp:\n",
    "            fp.write(\"\\n\".join(sentence_list))\n",
    "            \n",
    "        pbar.n += 1\n",
    "        pbar.refresh()\n",
    "        time.sleep(0.01)\n",
    "\n",
    "    pbar.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Size]\n",
      "The number of preprocessing corpus: 35\n",
      "\n",
      "[Order]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [03:55<00:00,  6.72s/it]\n"
     ]
    }
   ],
   "source": [
    "preprocessing_corpus_txt(pro_total_corpus_path_list, post_total_corpus_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_corpus_path = \"AIHUB_corpus/exploration/legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_post/AIHUB_legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data_\" +\"*.txt\"\n",
    "merge_corpus_path = 'AIHUB_corpus/duplicate/AIHUB_legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data.txt'\n",
    "deduplicate_corpus_path = 'AIHUB_corpus/AIHUB_legal_regulations_(such_as_terms_and_conditions_of_judgment)_text_analysis_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_and_deduplicate_corpus_txt(preprocessing_corpus_path, merge_corpus_path, \n",
    "                                  deduplicate_corpus_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus_06",
   "language": "python",
   "name": "corpus_06"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
