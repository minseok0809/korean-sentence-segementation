{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdmAO4oz4qg3"
      },
      "source": [
        "## AI Hub Json Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t46dEcpN4qg7"
      },
      "source": [
        "### Development Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I8JRGseV4qg7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import kss\n",
        "import json\n",
        "import MeCab\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from Korpora import Korpora"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LyrowP8W4qg8"
      },
      "source": [
        "### AIHUB 대규모 웹데이터 기반 한국어 말뭉치 데이터"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Source](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=624)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w0A-qS4P4qg9"
      },
      "outputs": [],
      "source": [
        "def json_file_name_list(path_list):\n",
        "    for i in path_list:\n",
        "        if 'rain' in i:\n",
        "            train_file_name = glob(i, recursive = True)\n",
        "        elif 'alid' in i:  \n",
        "            valid_file_name = glob(i, recursive = True)\n",
        "    return train_file_name, valid_file_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1RCPOh684qg9"
      },
      "outputs": [],
      "source": [
        "path_list = ['AIHUB_웹데이터 기반 한국어 말뭉치 데이터/Training/원천데이터/TS1/' + '**/*.json',\n",
        "             'AIHUB_웹데이터 기반 한국어 말뭉치 데이터/Validation/원천데이터/VS1/' + '**/*.json']\n",
        "train_file_name, valid_file_name = json_file_name_list(path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_corpus_txt(file_name_list, corpus_file_name):\n",
        "    sentence_list = []\n",
        "    for i in range(len(file_name_list)):\n",
        "        with open(file_name_list[i], 'r', encoding='utf-8') as one_json_file:\n",
        "            one_json_sample = json.load(one_json_file)\n",
        "        \n",
        "        source_list = list(pd.DataFrame(one_json_sample['SJML']['text'])['content'])\n",
        "        for source in source_list:\n",
        "            for sentence in kss.split_sentences(source):\n",
        "                if bool(re.match(r'[.]|[,]|[◆]|[◇]|[△]|[▲]|[▽]|[▼]|[▷]|[▶]|[<]|[>]', sentence[0])) == False:  \n",
        "                    sentence_list.append(sentence)  \n",
        "\n",
        "    with open(os.path.join('AIHUB_corpus/', corpus_file_name), \"a\", encoding='utf-8') as fp:        \n",
        "        fp.write(\"\\n\".join(sentence_list))              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "O_zBFtmL4qg_"
      },
      "outputs": [],
      "source": [
        "corpus_file_name = \"AIHUB_web_data_based_korean_corpus_data_source.txt\"\n",
        "make_corpus_txt(train_file_name, corpus_file_name)\n",
        "make_corpus_txt(valid_file_name, corpus_file_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fXi2O_X_4qhE"
      },
      "source": [
        "### AIHUB 기계독해"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Source](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PWIlfG5q4qhF"
      },
      "outputs": [],
      "source": [
        "def json_file_name_list(path_list):\n",
        "    for i in path_list:\n",
        "        file_name = glob(i, recursive = True)\n",
        "    return file_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v3oUViOf4qhF"
      },
      "outputs": [],
      "source": [
        "path_list = ['AIHUB_기계독해'+ '/**/*.json']\n",
        "file_name = json_file_name_list(path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ACZWujE24qhF"
      },
      "outputs": [],
      "source": [
        "def make_corpus_txt(file_name_list, corpus_file_name):\n",
        "\n",
        "    sentence_list = []\n",
        "    \n",
        "    for i in range(len(file_name_list)):\n",
        "        with open(file_name_list[i], 'r', encoding='utf-8') as one_json_file:\n",
        "            one_json_sample = json.load(one_json_file)\n",
        "\n",
        "            with open(os.path.join('AIHUB_corpus/', corpus_file_name), 'a', encoding=\"UTF-8\") as fp:\n",
        "                for j in one_json_sample['data']:\n",
        "                    for sentence in kss.split_sentences(j['paragraphs'][0]['context']):\n",
        "                        if bool(re.match(r'[.]|[,]|[◆]|[◇]|[△]|[▲]|[▽]|[▼]|[▷]|[▶]|[<]|[>]', sentence[0])) == False:  \n",
        "                            sentence_list.append(sentence) \n",
        "\n",
        "    with open(os.path.join('AIHUB_corpus/', corpus_file_name), \"a\", encoding='utf-8') as fp:        \n",
        "        fp.write(\"\\n\".join(sentence_list))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r8Y0TNOH4qhF"
      },
      "outputs": [],
      "source": [
        "corpus_file_name = \"AIHUB_machine_reading.txt\"\n",
        "make_corpus_txt(file_name, corpus_file_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AIHUB 요약문 및 레포트 생성 데이터"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Source](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=582)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_list = ['AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/01.news_r/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/02.briefing/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/03.his_cul/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/04.paper/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/05.minute/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/06.edit/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/07.public/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/08.speech/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/09.literature/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Training/원천데이터/TS1/10.narration/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/01.news_r/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/02.briefing/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/03.his_cul/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/04.paper/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/05.minute/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/06.edit/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/07.public/' + '**/*.json',             \n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/08.speech/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/09.literature/' + '**/*.json',\n",
        "'AIHUB_요약문 및 레포트 생성 데이터/Validation/원천데이터/VS1/10.narration/' + '**/*.json']\n",
        "\n",
        "train_file_name_01 = glob(path_list[0], recursive = True)\n",
        "train_file_name_02 = glob(path_list[1], recursive = True)\n",
        "train_file_name_03 = glob(path_list[2], recursive = True)\n",
        "train_file_name_04 = glob(path_list[3], recursive = True)\n",
        "train_file_name_05 = glob(path_list[4], recursive = True)\n",
        "train_file_name_06 = glob(path_list[5], recursive = True)\n",
        "train_file_name_07 = glob(path_list[6], recursive = True)\n",
        "train_file_name_08 = glob(path_list[7], recursive = True)\n",
        "train_file_name_09 = glob(path_list[8], recursive = True)\n",
        "train_file_name_10 = glob(path_list[9], recursive = True)\n",
        "valid_file_name_01 = glob(path_list[10], recursive = True)\n",
        "valid_file_name_02 = glob(path_list[11], recursive = True)\n",
        "valid_file_name_03 = glob(path_list[12], recursive = True)\n",
        "valid_file_name_04 = glob(path_list[13], recursive = True)\n",
        "valid_file_name_05 = glob(path_list[14], recursive = True)\n",
        "valid_file_name_06 = glob(path_list[15], recursive = True)\n",
        "valid_file_name_07 = glob(path_list[16], recursive = True)\n",
        "valid_file_name_08 = glob(path_list[17], recursive = True)\n",
        "valid_file_name_09 = glob(path_list[18], recursive = True)\n",
        "valid_file_name_10 = glob(path_list[19], recursive = True)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_corpus_txt(file_name_list, corpus_file_name):\n",
        "\n",
        "    sentence_list = []\n",
        "    \n",
        "    for i in range(len(file_name_list)):\n",
        "        with open(file_name_list[i], 'r', encoding='utf-8') as one_json_file:\n",
        "            one_json_sample = json.load(one_json_file)\n",
        "\n",
        "        for sentence in kss.split_sentences(one_json_sample['Meta(Refine)']['passage']):\n",
        "            if bool(re.match(r'[.]|[,]|[◆]|[◇]|[△]|[▲]|[▽]|[▼]|[▷]|[▶]|[<]|[>]', sentence[0])) == False:  \n",
        "                sentence_list.append(sentence) \n",
        "\n",
        "    with open(os.path.join('AIHUB_corpus/', corpus_file_name), \"a\", encoding='utf-8') as fp:        \n",
        "        fp.write(\"\\n\".join(sentence_list))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus_file_name = \"AIHUB_summary_and_report_generation_data.txt\"\n",
        "make_corpus_txt(train_file_name_01 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_02 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_03 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_04 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_05 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_06 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_07 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_08 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_09 , corpus_file_name)\n",
        "make_corpus_txt(train_file_name_10 , corpus_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "make_corpus_txt(valid_file_name_01 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_02 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_03 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_04 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_05 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_06 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_07 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_08 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_09 , corpus_file_name)\n",
        "make_corpus_txt(valid_file_name_10 , corpus_file_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vscode",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
